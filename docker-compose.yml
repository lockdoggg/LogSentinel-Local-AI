version: '3.8'

services:
  logsentinel:
    build: .
    container_name: logsentinel
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data  # Persist database and logs
    environment:
      # === AI CONFIGURATION ===
      # For Mac/Windows, use: [http://host.docker.internal:11434/api/chat](http://host.docker.internal:11434/api/chat)
      # For Linux, use: [http://172.17.0.1:11434/api/chat](http://172.17.0.1:11434/api/chat)
      - OLLAMA_URL=[http://host.docker.internal:11434/api/chat](http://host.docker.internal:11434/api/chat)
      
      # The model must be pulled in Ollama (e.g., 'ollama pull llama3')
      - MODEL_NAME=llama3
      
      # === SYSTEM ===
      # Change this to your timezone (e.g., America/New_York, Europe/Berlin)
      - TZ=UTC
      
      # === SECURITY ===
      # Leave empty to auto-generate a random secret on every restart.
      # Set a fixed string for persistent sessions across restarts.
      # - JWT_SECRET=my_production_secret_key
    extra_hosts:
      - "host.docker.internal:host-gateway" # Required for Linux to access host services
    restart: unless-stopped
